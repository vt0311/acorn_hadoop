hadoop 설치

# jdk 설치
tar -xvf /home/hadoop/Downloads/jdk-8u161-linux-i586.tar.gz 

# hadoop 설치
tar -xvf /home/hadoop/Downloads/hadoop-2.7.4.tar.gz

chown -R hadoop:hadoop /usr/local/jdk1.8.0_161/
chown -R hadoop:hadoop /usr/local/hadoop-2.7.4/


# 배시 프로파일 설정(.bash_profile)
export JAVA_HOME=/usr/local/jdk1.8.0_161

export HADOOP_HOME=/usr/local/hadoop-2.7.4
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native
export HADOOP_OPTS="-Djava.library.path=$HADOOP_HOME/lib"
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

export PATH=$PATH:$HADOOP_HOME/bin
export PATH=$PATH:$HADOOP_HOME/sbin

# HADOOP_HOME/libexec/hadoop-config.sh 의 첫 라인에 JAVA_HOME을 설정한다.
export JAVA_HOME=/usr/local/jdk1.8.0_161

# HADOOP_HOME/etc/hadoop/yarn-env.sh 의 첫 라인에 다음과 같이 경로를 편집한다.
export JAVA_HOME=/usr/local/jdk1.8.0_161
export HADOOP_HOME=/usr/local/hadoop-2.7.4
export HADOOP_MAPRED_HOME=$HADOOP_HOME
export HADOOP_COMMON_HOME=$HADOOP_HOME
export HADOOP_HDFS_HOME=$HADOOP_HOME
export YARN_HOME=$HADOOP_HOME
export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
export YARN_CONF_DIR=$HADOOP_HOME/etc/hadoop

# 하둡의 홈에 임시 폴더를 생성한다.
su -
mkdir -p /usr/local/hadoop-2.7.4/tmp
chown -R hadoop:hadoop /usr/local/hadoop-2.7.4/tmp

# HADOOP_HOME/etc/hadoop에서 다음과 같이 설정 파일을 편집한다.
# core-site.xml : HDFS와 맵 리듀스에 공통적으로 사용되는 IO 설정 같은 하둡 코어를 위한 환경 설정 구성
# vi core-site.xml 
<configuration>
<property>
<name>fs.default.name</name>
<value>hdfs://localhost:9000</value>
</property>
<property>
<name>hadoop.tmp.dir</name>
<value>/usr/local/hadoop-2.7.4/tmp</value>
</property>
</configuration>

# HDFS((Hadoop Distributed File System)와 관련된 파일
vi hdfs-site.xml
<configuration>
<property>
<name>dfs.replication</name>
<value>1</value>
</property>
<property>
<name>dfs.permissions</name>
<value>false</value>
</property>
</configuration>

# mapred-site.xml : MapReduce 프레임 워크와 관련된 파일이다. 
# 우선 제공해주는 기본 탬플릿 파일을 복사하도록 한다.
cp mapred-site.xml.template mapred-site.xml

vi mapred-site.xml

<configuration>
<property>
<name>Map/Reduce.framework.name</name>
<value>yarn</value>
</property>
</configuration>

vi yarn-site.xml
<configuration>
<property>
<name>yarn.nodemanager.aux-services</name>
<value>Map/Reduce_shuffle</value>
</property>
<property>
<name>yarn.nodemanager.aux-services.Map/Reduce_shuffle.class</name>
<value>org.apache.hadoop.mapred.ShuffleHandler</value>
</property>
</configuration>

# namenode를 포맷한다.
hdfs namenode -format
# ... 중략
# 18/01/29 06:00:00 INFO common.Storage: Storage directory 
# /usr/local/hadoop-2.7.4/tmp/dfs/name has been successfully formatted.

# 다음 명령어를 입력하여 hadoop를 실행한다.(sbin 폴더에 있는 것들)
hadoop-daemon.sh start namenode
hadoop-daemon.sh start datanode
yarn-daemon.sh start resourcemanager
yarn-daemon.sh start nodemanager
mr-jobhistory-daemon.sh start historyserver

# jps 명령어를 치면 다음과 같이 결과가 출력이 된다.
jps
14802 Jps
14179 NameNode
14762 JobHistoryServer
14397 ResourceManager
14303 DataNode

# 웹 브라우저에서 다음과 같이 입력을 수행해본다.
# 네임 노드(NameNode)에 대한 정보 보기
# 기본 포트는 50070
http://localhost:50070/

http://localhost:8088/